= データ活用してます？

== よくある光景。。。

上司：　WebAPサーバのレイテンシを測りたいんだよなー

先輩：　了解です！新人！Apacheのアクセスログを元に集計してみて！

新人：　へい( ﾟДﾟ)ゞﾋﾞｼｯ

先輩：　よろしくー

新人：　よしやるか！まずは、数十台のサーバからアクセスログを収集して。。Excelで集計して。。

（数時間後）

新人：つらたん。。Orz

こういった光景ってあると思うんですよね(筆者も昔経験したことがあります)。
たしかにこの方法でも集計できるのですが、集計するのに大きな工数がかかるのと確認するまでに時間がかかってしまいます。

理想は、Webアプリケーションサーバで出力されたログをリアルタイムに取り込み、ブラウザからいつでも確認できたらいいですよね。

え、そんなことできるの？本当にできるの？

…できるのです！
ログを取り込むための方法さえ知っていれば様々なログを可視化することができるのだーヽ(*ﾟдﾟ)ノ

ただ、ログを可視化するには、取り込むログを構造化し、収集する必要があります。
そこで、今回はLogstashを用いてお話ししていきます！
一度ログを取り込んでしまえば、あとは好きなように可視化すればいいのです！


== Logstash
Logstashは、Elastic社が提供するオープンソースログ収集管理ツールです。
取り込み先としては、同じElastic社製の検索エンジン@<code>{Elasticsearch}と組み合わせることでニアリアルタイムにログを取り込むことができます。

Logstashでログを収集する流れの一例を@<img>{stage02-01}に示します。

//image[stage02-01][Logstashの構造#01]{
  Logstashの構造の図を追加
//}

@<img>{stage02-02}はLogstashの処理の流れを示したものです。LogstashはINPUTS・FILTERS・OUTPUTSの
流れでデータを処理します。

//image[stage02-02][Logstashの構造#02]{
//}


=== INPUTS
大抵の場合、Logstashのデータソースとなるログは多様な形式で分散されていることがほとんどです。
Logstashを利用すれば、様々なデータ形式に対応できます。
例えば、ソフトウェアのログ・サーバのメトリクス情報・Webアプリケーションのデータ・データストア・様々なクラウドサービスなどから
データを収集できます。


=== FILTERS
INPUTしたデータソースをLogstashのFilterで解析し、構造化します。
#@#フィールドを識別するっていきなりでてくるとわかりにくい+無くても繋がるのでとりました。入れるならfieldsについて説明が欲しいかも。
データソースの変換には、正規表現でデータをパースするためのfilterプラグイン@<code>{grok（以降Grok Filterと表記）}
やIPアドレスから地理情報を得るためのfilterプラグイン@<code>{Geoip（以降Geoip Filterと表記）}など様々なフィルタライブラリ
（@<href>{https://www.elastic.co/guide/en/logstash/current/filter-plugins.html}）が用意されています。
くどいですが、このGrok Filterにフォーカスします！

=== OUTPUTS
データを構造化したのち、任意の出力先にデータを送付します。
Elasticsearch以外の出力先も多数提供されているので、環境に合わせてデータを送付できます。

ここまででなんとなーくLogstashについてわかりましたか？
要は、インプットデータをLogstashに食べさせると、定義したフィルタを介してデータを構造化し、出力先に指定したところに転送してくれるって感じですね。

それでは、次章では実際にLogstashに触れていきたいと思います。
